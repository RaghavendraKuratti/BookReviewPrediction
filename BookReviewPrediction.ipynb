{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSilYBIEnebYPxMSS1rszA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaghavendraKuratti/BookReviewPrediction/blob/main/BookReviewPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "p8CKOjlFX0ix",
        "outputId": "043a1b93-6462-497f-ad76-edee293b5f84"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "class Sentiment:\r\n",
        "\tPOSITIVE = \"POSITIVE\"\r\n",
        "\tNEGATIVE = \"NEGATIVE\"\r\n",
        "\tNEUTRAL = \"NEUTRAL\"\r\n",
        "\t\t\r\n",
        "class Review:\r\n",
        "\t# \"docstring for Review\"\r\n",
        "\tdef __init__(self, text, rate):\r\n",
        "\t\tself.text = text\r\n",
        "\t\tself.rate = rate\r\n",
        "\t\tself.sentiment = self.get_sentiment()\r\n",
        "\r\n",
        "\tdef get_sentiment(self):\r\n",
        "\t\tif self.rate <= 2:\r\n",
        "\t\t\treturn Sentiment.NEGATIVE\r\n",
        "\t\telif self.rate == 3:\r\n",
        "\t\t\treturn Sentiment.NEUTRAL\r\n",
        "\t\telif self.rate > 3:\r\n",
        "\t\t\treturn Sentiment.POSITIVE\r\n",
        "\t\t\r\n",
        "class ReviewCounter:\r\n",
        "\tdef __init__(self, reviews):\r\n",
        "\t\tself.reviews = reviews\r\n",
        "\r\n",
        "\tdef get_text(self):\r\n",
        "\t\treturn [x.text for x in  self.reviews]\r\n",
        "\r\n",
        "\tdef get_y(self):\r\n",
        "\t\treturn [x.sentiment for x in  self.reviews]\r\n",
        "\r\n",
        "\tdef evenly_distrubute(self):\r\n",
        "\t\tnegative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\r\n",
        "\t\tpositive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\r\n",
        "\t\tpositive = positive[:len(negative)]\r\n",
        "\t\tself.reviews = negative + positive\r\n",
        "\t\trandom.shuffle(self.reviews)\r\n",
        "\r\n",
        "import pandas as pd \r\n",
        "import json\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "\r\n",
        "file_name = \"Books_small_10000.json\"\r\n",
        "reviews = []\r\n",
        "with open(file_name) as f:\r\n",
        "\tfor line in f:\r\n",
        "\t\treview = json.loads(line)\r\n",
        "\t\treviews.append(Review(review[\"reviewText\"],review[\"overall\"]))\r\n",
        "training, testing = train_test_split(reviews, test_size=0.33, random_state=42)\r\n",
        "\r\n",
        "train_cont = ReviewCounter(training)\r\n",
        "train_cont.evenly_distrubute()\r\n",
        "test_cont = ReviewCounter(testing)\r\n",
        "test_cont.evenly_distrubute()\r\n",
        "\r\n",
        "train_x = train_cont.get_text()\r\n",
        "train_y = train_cont.get_y()\r\n",
        "\r\n",
        "test_x = test_cont.get_text()\r\n",
        "test_y = test_cont.get_y()\r\n",
        "\r\n",
        "vectorizer = CountVectorizer()\r\n",
        "train_data_vect = vectorizer.fit_transform(train_x)\r\n",
        "test_data_vect = vectorizer.transform(test_x)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "from sklearn import svm\r\n",
        "clf_svm = svm.SVC(kernel=\"linear\")\r\n",
        "clf_svm.fit(train_data_vect,train_y)\r\n",
        "result = clf_svm.predict(test_data_vect[0])\r\n",
        "# print(result)\r\n",
        "\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "clf_dt = DecisionTreeClassifier()\r\n",
        "clf_dt.fit(train_data_vect,train_y)\r\n",
        "result = clf_dt.predict(test_data_vect[0])\r\n",
        "# print(result)\r\n",
        "\r\n",
        "# from sklearn.naive_bayes import GaussianNB\r\n",
        "# clf_gnb = GaussianNB()\r\n",
        "# clf_gnb.fit(train_data_vect,train_y)\r\n",
        "# result = clf_gnb.predict(test_data_vect)\r\n",
        "# print(result)\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "clf_lr = LogisticRegression()\r\n",
        "clf_lr.fit(train_data_vect,train_y)\r\n",
        "result = clf_lr.predict(test_data_vect[0])\r\n",
        "# print(result)\r\n",
        "\r\n",
        "# print(clf_svm.score(test_data_vect,test_y))\r\n",
        "# print(clf_dt.score(test_data_vect,test_y))\r\n",
        "# print(clf_lr.score(test_data_vect,test_y))\r\n",
        "\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "# print(f1_score(test_y, clf_svm.predict(test_data_vect), average=None,labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\r\n",
        "# print(f1_score(test_y, clf_dt.predict(test_data_vect), average=None,labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\r\n",
        "# print(f1_score(test_y, clf_lr.predict(test_data_vect), average=None,labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\r\n",
        "\r\n",
        "test_set = [\"kuratti is a good person\", \"kuratti is a junk person\", \"dumb person\"]\r\n",
        "new_test = vectorizer.transform(test_set)\r\n",
        "result = clf_svm.predict(new_test)\r\n",
        "# print(result)\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\r\n",
        "svc = svm.SVC()\r\n",
        "clf = GridSearchCV(svc, parameters, cv=5)\r\n",
        "clf.fit(train_data_vect,train_y)\r\n",
        "# print(f1_score(test_y, clf.predict(test_data_vect), average=None,labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\r\n",
        "# import pickle\r\n",
        "# # with open('./Models/sentiment_classifier.pkl', 'wb') as f:\r\n",
        "# # \tpickle.dump(clf, f)\r\n",
        "# with open('./Models/vector.pkl', 'rb') as f:\r\n",
        "# \tvector = pickle.load(f)\r\n",
        "# test_list = [\"Im bad\"]\r\n",
        "# test_data = vector.transform(test_list)\r\n",
        "# with open('./Models/sentiment_classifier.pkl', 'rb') as f:\r\n",
        "# \tloaded_pkl = pickle.load(f)\r\n",
        "\r\n",
        "# print(loaded_pkl.predict(test_data)[0])\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4d3b685cae3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Books_small_10000.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Books_small_10000.json'"
          ]
        }
      ]
    }
  ]
}